{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "W24CTLN9ARPd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "sys.argv\n",
        "import argparse\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "import math\n",
        "import dlib\n",
        "from PIL import Image,ImageFile\n",
        "\n",
        "__version__ = '0.3.0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yo3JRkmxDYzl",
        "outputId": "58bf1946-cba5-4ffa-e7a3-4f9e0174912f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install patool\n",
        "import patoolib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wj1IcQ0ydG8",
        "outputId": "73035c3f-148a-43a9-e10d-2013d98295c0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting patool\n",
            "  Downloading patool-1.12-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.5/77.5 KB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-1.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patoolib.extract_archive('Dataset_svt.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "5p2OpS5wy5Oh",
        "outputId": "1e023cc5-4015-4ecf-9218-ba4359350e94"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "patool: Extracting Dataset_svt.zip ...\n",
            "patool: running /usr/bin/7z x -o./Unpack_v3es26zg -- Dataset_svt.zip\n",
            "patool: ... Dataset_svt.zip extracted to `Dataset_svt' (multiple files in root).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Dataset_svt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patoolib.extract_archive('wenjunhui.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "3kyrrOScxnTv",
        "outputId": "8e28ef45-bee9-4cac-fcc9-e8d34669704f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "patool: Extracting wenjunhui.zip ...\n",
            "patool: running /usr/bin/7z x -o./Unpack_yv8pbj0s -- wenjunhui.zip\n",
            "patool: ... wenjunhui.zip extracted to `wenjunhui'.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'wenjunhui'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuzdshYAo5k7",
        "outputId": "66efafea-f1c2-465f-cefd-5fa4b85ac701"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Real-World-Masked-Face-Dataset'...\n",
            "remote: Enumerating objects: 1417, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 1417 (delta 7), reused 1 (delta 0), pack-reused 1401\u001b[K\n",
            "Receiving objects: 100% (1417/1417), 180.93 MiB | 23.15 MiB/s, done.\n",
            "Resolving deltas: 100% (160/160), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/X-zhangyang/Real-World-Masked-Face-Dataset.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qIxodPx7-vF",
        "outputId": "65beb084-07f7-4207-8bf5-6c221bb010ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'face_recognition_models'...\n",
            "remote: Enumerating objects: 57, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 57 (delta 8), reused 9 (delta 4), pack-reused 41\u001b[K\n",
            "Unpacking objects: 100% (57/57), done.\n",
            "Checking out files: 100% (16/16), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ageitgey/face_recognition_models.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALpkQR5Y4LlI",
        "outputId": "13f86a54-a0f9-4159-8037-018bf14581c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting face_recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.8/dist-packages (from face_recognition) (7.1.2)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.8/dist-packages (from face_recognition) (19.24.0)\n",
            "Collecting face-recognition-models>=0.3.0\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from face_recognition) (1.21.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from face_recognition) (7.1.2)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566185 sha256=af8d2b4d9a6f078ac1c7cc2082873fb3b66140e971c9f20dbc08e83a37af9377\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/4b/8f/751e99d45f089bdf366a7d3e5066db3c2b84a62e4377f534d7\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face_recognition\n",
            "Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install face_recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtPJyuaO5hBQ",
        "outputId": "5fa51d24-b454-4325-be3e-f7aa383961ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.8/dist-packages (3.22.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install cmake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lu1AJCziAjQR"
      },
      "outputs": [],
      "source": [
        "IMAGE_DIR = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), '/content/Real-World-Masked-Face-Dataset/wear_mask_to_face/images')\n",
        "\n",
        "DEFAULT_IMAGE_PATH = os.path.join(IMAGE_DIR, '/content/Real-World-Masked-Face-Dataset/wear_mask_to_face/images/default-mask.png')\n",
        "BLACK_IMAGE_PATH =  os.path.join(IMAGE_DIR, '/content/Real-World-Masked-Face-Dataset/wear_mask_to_face/images/black-mask.png')\n",
        "BLUE_IMAGE_PATH =  os.path.join(IMAGE_DIR, '/content/Real-World-Masked-Face-Dataset/wear_mask_to_face/images/blue-mask.png')\n",
        "RED_IMAGE_PATH =  os.path.join(IMAGE_DIR, '/content/Real-World-Masked-Face-Dataset/wear_mask_to_face/images/red-mask.png')\n",
        "\n",
        "\n",
        "def rect_to_bbox(rect):\n",
        "    # print(rect)\n",
        "    x = rect[3]\n",
        "    y = rect[0]\n",
        "    w = rect[1] - x\n",
        "    h = rect[2] - y\n",
        "    return (x, y, w, h)\n",
        "\n",
        "\n",
        "def face_alignment(faces):\n",
        "    #Predict Key Points\n",
        "    predictor = dlib.shape_predictor('/content/face_recognition_models/face_recognition_models/models/shape_predictor_68_face_landmarks.dat')\n",
        "    faces_aligned = []\n",
        "    for face in faces:\n",
        "        rec = dlib.rectangle(0, 0, face.shape[0], face.shape[1])\n",
        "        shape = predictor(np.uint8(face), rec)\n",
        "        # left eye, right eye, nose, left mouth, right mouth\n",
        "        order = [36, 45, 30, 48, 54]\n",
        "        for j in order:\n",
        "            x = shape.part(j).x\n",
        "            y = shape.part(j).y\n",
        "        # Calculate the center coordinates of the two eyes\n",
        "        eye_center = ((shape.part(36).x + shape.part(45).x) * 1. / 2, (shape.part(36).y + shape.part(45).y) * 1. / 2)\n",
        "        dx = (shape.part(45).x - shape.part(36).x)\n",
        "        dy = (shape.part(45).y - shape.part(36).y)\n",
        "        # calculate angle\n",
        "        angle = math.atan2(dy, dx) * 180. / math.pi\n",
        "        # Compute the affine matrix\n",
        "        RotateMatrix = cv2.getRotationMatrix2D(eye_center, angle, scale=1)\n",
        "        # Perform an affine transformation, that is, rotate\n",
        "        RotImg = cv2.warpAffine(face, RotateMatrix, (face.shape[0], face.shape[1]))\n",
        "        faces_aligned.append(RotImg)\n",
        "    return faces_aligned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-C1qdVL_BE26"
      },
      "outputs": [],
      "source": [
        "def cli(pic_path, save_pic_path):\n",
        "    parser = argparse.ArgumentParser(description='Wear a face mask in the given picture.')\n",
        "    \n",
        "    parser.add_argument('--model', default='hog', choices=['hog', 'cnn'], help='Which face detection model to use.')\n",
        "    group = parser.add_mutually_exclusive_group()\n",
        "    group.add_argument('--black', action='store_true', help='Wear black mask')\n",
        "    group.add_argument('--blue', action='store_true', help='Wear blue mask')\n",
        "    group.add_argument('--red', action='store_true', help='Wear red mask')\n",
        "    parser.add_argument(\"-f\", required=False)\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    if not os.path.exists(pic_path):\n",
        "        print(f'Picture {pic_path} not exists.')\n",
        "        sys.exit(1)\n",
        "\n",
        "    #if args.black:\n",
        "          #mask_path = BLACK_IMAGE_PATH\n",
        "    #elif args.blue:\n",
        "          #mask_path = BLUE_IMAGE_PATH\n",
        "    #elif args.red:\n",
        "          #mask_path = RED_IMAGE_PATH\n",
        "    #else:\n",
        "          #mask_path = DEFAULT_IMAGE_PATH\n",
        "    mask_path = DEFAULT_IMAGE_PATH\n",
        "    print(pic_path,mask_path)\n",
        "    print(save_pic_path)\n",
        "    unmasked_paths = FaceMasker(pic_path, mask_path, True, 'cnn',save_pic_path).mask()\n",
        "    return unmasked_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "g_su-m3RBFY7"
      },
      "outputs": [],
      "source": [
        "class FaceMasker:\n",
        "    KEY_FACIAL_FEATURES = ('nose_bridge', 'chin')\n",
        "\n",
        "    def __init__(self, face_path, mask_path, show=False, model='cnn',save_path = ''):\n",
        "        self.face_path = face_path\n",
        "        self.mask_path = mask_path\n",
        "        self.save_path = save_path\n",
        "        self.show = show\n",
        "        self.model = model\n",
        "        self._face_img: ImageFile = None\n",
        "        self._mask_img: ImageFile = None\n",
        "\n",
        "    def mask(self):\n",
        "        import face_recognition\n",
        "\n",
        "        face_image_np = face_recognition.load_image_file(self.face_path)\n",
        "        face_locations = face_recognition.face_locations(face_image_np, model=self.model)\n",
        "        face_landmarks = face_recognition.face_landmarks(face_image_np, face_locations)\n",
        "        self._face_img = Image.fromarray(face_image_np)\n",
        "        self._mask_img = Image.open(self.mask_path)\n",
        "\n",
        "        found_face = False\n",
        "        for face_landmark in face_landmarks:\n",
        "            # check whether facial features meet requirement\n",
        "            skip = False\n",
        "            for facial_feature in self.KEY_FACIAL_FEATURES:\n",
        "                if facial_feature not in face_landmark:\n",
        "                    skip = True\n",
        "                    break\n",
        "            if skip:\n",
        "                continue\n",
        "\n",
        "            # mask face\n",
        "            found_face = True\n",
        "            self._mask_face(face_landmark)\n",
        "\n",
        "        unmasked_paths = []\n",
        "        if found_face:\n",
        "            # align\n",
        "            src_faces = []\n",
        "            src_face_num = 0\n",
        "            with_mask_face = np.asarray(self._face_img)\n",
        "            for (i, rect) in enumerate(face_locations):\n",
        "                src_face_num = src_face_num + 1\n",
        "                (x, y, w, h) = rect_to_bbox(rect)\n",
        "                detect_face = with_mask_face[y:y + h, x:x + w]\n",
        "                src_faces.append(detect_face)\n",
        "            # Face alignment operation and save\n",
        "            faces_aligned = face_alignment(src_faces)\n",
        "            face_num = 0\n",
        "            for faces in faces_aligned:\n",
        "                face_num = face_num + 1\n",
        "                faces = cv2.cvtColor(faces, cv2.COLOR_RGBA2BGR)\n",
        "                size = (int(128), int(128))\n",
        "                faces_after_resize = cv2.resize(faces, size, interpolation=cv2.INTER_AREA)\n",
        "                cv2.imwrite('/content/savedata'+str(face_num)+'.jpg', faces_after_resize)\n",
        "            # if self.show:\n",
        "            #     self._face_img.show()\n",
        "            # save\n",
        "            # self._save()\n",
        "        else:\n",
        "            #Record the uncropped picture here\n",
        "            print('Found no face.'+self.save_path)\n",
        "            unmasked_paths.append(self.save_path)\n",
        "            return unmasked_paths\n",
        "            \n",
        "    def _mask_face(self, face_landmark: dict):\n",
        "        nose_bridge = face_landmark['nose_bridge']\n",
        "        nose_point = nose_bridge[len(nose_bridge) * 1 // 4]\n",
        "        nose_v = np.array(nose_point)\n",
        "\n",
        "        chin = face_landmark['chin']\n",
        "        chin_len = len(chin)\n",
        "        chin_bottom_point = chin[chin_len // 2]\n",
        "        chin_bottom_v = np.array(chin_bottom_point)\n",
        "        chin_left_point = chin[chin_len // 8]\n",
        "        chin_right_point = chin[chin_len * 7 // 8]\n",
        "\n",
        "        # split mask and resize\n",
        "        width = self._mask_img.width\n",
        "        height = self._mask_img.height\n",
        "        width_ratio = 1.2\n",
        "        new_height = int(np.linalg.norm(nose_v - chin_bottom_v))\n",
        "\n",
        "        # left\n",
        "        mask_left_img = self._mask_img.crop((0, 0, width // 2, height))\n",
        "        mask_left_width = self.get_distance_from_point_to_line(chin_left_point, nose_point, chin_bottom_point)\n",
        "        mask_left_width = int(mask_left_width * width_ratio)\n",
        "        mask_left_img = mask_left_img.resize((mask_left_width, new_height))\n",
        "\n",
        "        # right\n",
        "        mask_right_img = self._mask_img.crop((width // 2, 0, width, height))\n",
        "        mask_right_width = self.get_distance_from_point_to_line(chin_right_point, nose_point, chin_bottom_point)\n",
        "        mask_right_width = int(mask_right_width * width_ratio)\n",
        "        mask_right_img = mask_right_img.resize((mask_right_width, new_height))\n",
        "\n",
        "        # merge mask\n",
        "        size = (mask_left_img.width + mask_right_img.width, new_height)\n",
        "        mask_img = Image.new('RGBA', size)\n",
        "        mask_img.paste(mask_left_img, (0, 0), mask_left_img)\n",
        "        mask_img.paste(mask_right_img, (mask_left_img.width, 0), mask_right_img)\n",
        "\n",
        "        # rotate mask\n",
        "        angle = np.arctan2(chin_bottom_point[1] - nose_point[1], chin_bottom_point[0] - nose_point[0])\n",
        "        rotated_mask_img = mask_img.rotate(angle, expand=True)\n",
        "\n",
        "        # calculate mask location\n",
        "        center_x = (nose_point[0] + chin_bottom_point[0]) // 2\n",
        "        center_y = (nose_point[1] + chin_bottom_point[1]) // 2\n",
        "\n",
        "        offset = mask_img.width // 2 - mask_left_img.width\n",
        "        radian = angle * np.pi / 180\n",
        "        box_x = center_x + int(offset * np.cos(radian)) - rotated_mask_img.width // 2\n",
        "        box_y = center_y + int(offset * np.sin(radian)) - rotated_mask_img.height // 2\n",
        "\n",
        "        # add mask\n",
        "        self._face_img.paste(mask_img, (box_x, box_y), mask_img)\n",
        "\n",
        "    def _save(self):\n",
        "        path_splits = os.path.splitext(self.face_path)\n",
        "        new_face_path = path_splits[0] + '-with-mask' + path_splits[1]\n",
        "        self._face_img.save(new_face_path)\n",
        "        print(f'Save to {new_face_path}')\n",
        "\n",
        "    @staticmethod\n",
        "    def get_distance_from_point_to_line(point, line_point1, line_point2):\n",
        "        distance = np.abs((line_point2[1] - line_point1[1]) * point[0] +\n",
        "                          (line_point1[0] - line_point2[0]) * point[1] +\n",
        "                          (line_point2[0] - line_point1[0]) * line_point1[1] +\n",
        "                          (line_point1[1] - line_point2[1]) * line_point1[0]) / \\\n",
        "                   np.sqrt((line_point2[1] - line_point1[1]) * (line_point2[1] - line_point1[1]) +\n",
        "                           (line_point1[0] - line_point2[0]) * (line_point1[0] - line_point2[0]))\n",
        "        return int(distance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "PUhk0GWwBO7M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3062b564-317e-4bca-d3ec-b002af77e4a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Dataset_svt/dino.jpg /content/Real-World-Masked-Face-Dataset/wear_mask_to_face/images/default-mask.png\n",
            "/content/savedata\n",
            "Found no face./content/savedata\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    #dataset_path = '/content/tes'\n",
        "    save_dataset_path = '/content/savedata'\n",
        "    imgpath = '/content/Dataset_svt/dino.jpg'\n",
        "    cli(imgpath, save_dataset_path)\n",
        "    #for root, dirs, files in os.walk(dataset_path, topdown=False):\n",
        "        #for name in files:\n",
        "            #new_root = root.replace(dataset_path, save_dataset_path)\n",
        "            # if not os.path.exists(new_root):\n",
        "            #     os.makedirs(new_root)\n",
        "            # deal\n",
        "            #imgpath = os.path.join(root, name)\n",
        "            #save_imgpath = os.path.join(new_root, name)\n",
        "            #cli(imgpath,save_imgpath)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5SSUv6W4yS8Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}